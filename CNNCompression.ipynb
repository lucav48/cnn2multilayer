{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bkLTgMJ6i_Hp"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "import math\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.colors as mcolors\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ju5K9_wIkFPM"
   },
   "source": [
    "____\n",
    "# CUT LAYERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q3Vh1dDjkGrw",
    "outputId": "48b948bc-4abf-42a0-d1ea-676b3e029c0d"
   },
   "outputs": [],
   "source": [
    "graphs = {}\n",
    "dataset = \"cifar100\"\n",
    "model = \"ResNet110v2\"\n",
    "# specify folder path where files of an execution of cnn2multilayer are stored\n",
    "path = \"\"\n",
    "for f in tqdm(os.listdir(path)):\n",
    "    # read csv file to graph\n",
    "    if \".csv\" in f and model in f and len(graphs) < 88:\n",
    "      print(f)\n",
    "      df = pd.read_csv(path + f)\n",
    "      df[\"edge\"] = df[\"edge\"].str.replace(\"(\", \"\")\n",
    "      df[\"edge\"] = df[\"edge\"].str.replace(\")\", \"\")\n",
    "      df[[\"source\", \"target\"]] = df.edge.str.split(\", \", expand=True)\n",
    "      df = df.drop([\"edge\"], axis=1)\n",
    "      graphs[int(f.split(\"_\")[1].replace(\".csv\", \"\"))] = nx.from_pandas_edgelist(df, source=\"source\", target=\"target\", edge_attr=[\"mean\", \"0.5\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sW7BVkP0kSpj"
   },
   "outputs": [],
   "source": [
    "base_graph = nx.read_gexf(path + dataset + \"-\" + model + \".gexf\")\n",
    "# uniformare i nomi dei convoluzionali\n",
    "for node in base_graph.nodes(data=True):\n",
    "    if dataset not in [\"mnist\", \"cifar10\", \"cifar100\"]:\n",
    "        layer = node[1][\"layer\"]\n",
    "        block_id = int(layer.split(\"_\")[0].replace(\"block\", \"\"))\n",
    "        conv_id = int(layer.split(\"_\")[1].replace(\"conv\", \"\"))\n",
    "        if block_id <= 2:\n",
    "            real_id = (block_id - 1) * 2 + conv_id\n",
    "        else:\n",
    "            real_id = (block_id - 3) * 3 + 4 + conv_id\n",
    "        base_graph.nodes[node[0]][\"old_layer\"] = layer\n",
    "        base_graph.nodes[node[0]][\"layer\"] = \"conv2d_\" + str(real_id)\n",
    "    else:\n",
    "        base_graph.nodes[node[0]][\"old_layer\"] = node[1][\"layer_name\"]\n",
    "        base_graph.nodes[node[0]][\"layer\"] = node[1][\"layer_name\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p5UmZ6_ekted"
   },
   "source": [
    "## DESCRIPTIVE ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 528
    },
    "id": "ERQfu9hPkpR1",
    "outputId": "09ff924e-be45-4270-d99c-5c0e7753363a"
   },
   "outputs": [],
   "source": [
    "print('Number of nodes:', len(graphs[1].nodes))\n",
    "print('Number of arcs:', len(graphs[1].edges))\n",
    "print('Density:', nx.density(graphs[1]))\n",
    "print('Clustering:', nx.average_clustering(graphs[1]))\n",
    "print('Is connected?:', nx.is_connected(graphs[1].to_undirected()))\n",
    "print('3-core nodes:', len(list(nx.k_core(graphs[1], k=3).nodes)))\n",
    "print('4-core nodes:', len(list(nx.k_core(graphs[1], k=4).nodes)))\n",
    "print('5-core nodes:', len(list(nx.k_core(graphs[1], k=5).nodes)))\n",
    "print('6-core nodes:', len(list(nx.k_core(graphs[1], k=6).nodes)))\n",
    "print('9-core nodes:', len(list(nx.k_core(graphs[1], k=9).nodes)))\n",
    "print('12-core nodes:', len(list(nx.k_core(graphs[1], k=12).nodes)))\n",
    "sns.distplot(list(nx.clustering(graphs[1]).values()), kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_x_q2uX5kuyB"
   },
   "outputs": [],
   "source": [
    "# arcs dataframe\n",
    "data = {}\n",
    "for k, graph in graphs.items():\n",
    "    df = pd.DataFrame(nx.get_edge_attributes(graph,'mean'), index=[0]).T\n",
    "    df = df.rename({0: 'mean'}, axis=1)\n",
    "    df['0.5'] = nx.get_edge_attributes(graph,'0.5').values()\n",
    "    data[k] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZUrmKc-WY6pU",
    "outputId": "065a4cc2-df96-46b8-f055-56ce59c8f3b0"
   },
   "outputs": [],
   "source": [
    "df[\"mean\"].describe(), df[\"0.5\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pm4YmWaPlVSH"
   },
   "source": [
    "##  COOL LAYERS FROM MULTILAYER NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3hXFceX-lWvM"
   },
   "outputs": [],
   "source": [
    "# degree by sum for all layers, mean for all layers, entropy\n",
    "weight_type = \"mean\"\n",
    "threshold_type = \"mean\"\n",
    "entropy = False\n",
    "\n",
    "nodes = {k:0 for k in list(base_graph.nodes)}\n",
    "\n",
    "for label, graph in graphs.items():\n",
    "    node_degree = dict(graph.degree(weight=weight_type))\n",
    "    for k, v in node_degree.items():\n",
    "      nodes[k] = nodes[k] + v\n",
    "\n",
    "if entropy:\n",
    "    for node, total_degree in nodes.items():\n",
    "        entropy = 0\n",
    "        for label, graph in graphs.items():\n",
    "            try:\n",
    "                ratio = graph.degree(node, weight=weight_type) / total_degree\n",
    "                entropy += ratio * math.log(ratio, 2)\n",
    "            except:\n",
    "                entropy += 0\n",
    "        entropy *= -1\n",
    "        nodes[node] = entropy\n",
    "else:  \n",
    "  if weight_type == \"sum\":\n",
    "      pass\n",
    "  elif weight_type == \"mean\":\n",
    "      for k, v in nodes.items():\n",
    "          nodes[k] = v / len(graphs)\n",
    "  elif weight_type == \"0.5\":\n",
    "      for k, v in nodes.items():\n",
    "          if len(nodes[k]) > 0:\n",
    "              nodes[k] = statistics.median(nodes[k])\n",
    "          else:\n",
    "              nodes[k] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XBv2p4UAldpB"
   },
   "outputs": [],
   "source": [
    "total_layers = list(set([x[1][\"layer_name\"] for x in base_graph.nodes(data=True)]))\n",
    "\n",
    "# lol contains for each threshold the layer to remove and other information\n",
    "lol = {}\n",
    "for th, i in zip(np.arange(.05, 8., 0.05), range(len(np.arange(.05, 8., 0.05)))):\n",
    "    # mean\n",
    "    threshold = statistics.median(list(nodes.values())) * th\n",
    "    cool_nodes = []\n",
    "    cool_layers = []\n",
    "    count_layers = {}\n",
    "    for k, v in nodes.items():\n",
    "        if v >= threshold:\n",
    "            layer = base_graph.nodes[k][\"layer_name\"]\n",
    "            cool_nodes.append(k)\n",
    "            cool_layers.append(layer)\n",
    "            if layer in count_layers:\n",
    "                count_layers[layer] = count_layers[layer] + 1\n",
    "            else:\n",
    "                count_layers[layer] = 0\n",
    "            \n",
    "    lol[i] = {\"th\": round(th, 2),\n",
    "              \"n_convs\": len(set(total_layers).difference(set(cool_layers))),\n",
    "              \"convs\": list(set(total_layers).difference(set(cool_layers))),\n",
    "              \"dataset\": dataset,\n",
    "              \"model\": model\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jlLqj40nOp4d"
   },
   "outputs": [],
   "source": [
    "dis = {}\n",
    "c = 0\n",
    "for i in range(1, len(lol)):\n",
    "  if lol[i-1][\"n_convs\"] != lol[i][\"n_convs\"]:\n",
    "    dis[c] = lol[i]\n",
    "    c+= 1\n",
    "dis = pd.DataFrame.from_dict(dis, orient=\"index\")\n",
    "dis.to_csv(\"cut-\" + dataset + \"-\" + model + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kDObaoCWisax"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
